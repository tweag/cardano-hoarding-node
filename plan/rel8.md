# Plan: Add Rel8 Database Effects

## Overview

Add Rel8 to the Cardano hoarding node project and create DBRead and DBWrite effects, adapting the provided Polysemy-based code to work with Effectful.

## Steps

### 1. Add Dependencies to package.yaml

Add the following database-related dependencies:
- `rel8` - Type-safe query builder on top of Hasql
- `hasql` - PostgreSQL driver
- `hasql-pool` - Connection pooling
- `hasql-transaction` - Transaction support

### 2. Create Database Configuration Type

Create `src/Hoard/Types/DBConfig.hs` with:
- `DBConfig` data type containing:
  - `host :: Text` - Database host
  - `port :: Port` - Database port
  - `user :: Text` - Database user
  - `password :: Text` - Database password
  - `databaseName :: Text` - Database name
- Helper type `Port` and conversion function `portToWord16`
- `acquireDatabasePool :: DBConfig -> IO Pool` function for creating connection pools

Pool configuration:
- Size: 10 connections
- Acquisition timeout: 5 seconds
- Aging timeout: 30 minutes (maximal connection lifetime)
- Idleness timeout: 10 minutes (maximal connection idle time)

### 3. Create DBRead Effect

Create `src/Hoard/Effects/DBRead.hs` with:
- Effect definition:
  ```haskell
  data DBRead :: Effect where
    RunQuery :: Text -> Statement () b -> DBRead m b
  ```
- Handler `runDBRead :: Pool -> Eff (DBRead : es) a -> Eff es a` that:
  - Executes read-only queries using the connection pool
  - Logs query execution time
  - Handles errors by throwing appropriate exceptions
  - Uses `Hasql.Pool.use` to acquire connections from the pool

### 4. Create DBWrite Effect

Create `src/Hoard/Effects/DBWrite.hs` with:
- Effect definition:
  ```haskell
  data DBWrite :: Effect where
    RunTransaction :: Text -> Transaction a -> DBWrite m a
  ```
- Handler `runDBWrite :: Pool -> Eff (DBWrite : es) a -> Eff es a` that:
  - Executes write transactions with `ReadCommitted` isolation level and `Write` mode
  - Logs transaction execution time
  - Handles errors by logging failure details and throwing exceptions
  - Uses `Hasql.Transaction.Sessions.transaction` for ACID guarantees

### 5. Update Effect Stack

Modify `src/Hoard/Effects.hs` to:
- Add `connectionPool :: Pool` to the `Config` data type
- Add `DBRead :> es` and `DBWrite :> es` to the `AppEff` constraint
- Add `DBRead` and `DBWrite` to the `AppEffects` type list
- Integrate `runDBRead` and `runDBWrite` handlers into `runEffectStack` and `runEffectStackReturningState`
- Ensure proper ordering in the effect stack (database effects should be near the top, after State but before lower-level effects)

## Key Differences from Provided Code

The provided code uses Polysemy, but this project uses Effectful. Key adaptations:

1. **Effect definitions**: Use `data EffectName :: Effect where` instead of `data EffectName m a where`
2. **Effect constraint**: Use `(:>)` from Effectful instead of Polysemy's `Member`
3. **Handlers**: Use `Eff` monad and Effectful's interpretation functions
4. **No makeSem**: Effectful uses different TH for effect operations
5. **Error handling**: Adapt to Effectful's error handling patterns
6. **Logging**: Will need to integrate with existing logging (if any) or add logging effect

## Files to Create

1. `src/Hoard/Types/DBConfig.hs` - Database configuration
2. `src/Hoard/Effects/DBRead.hs` - Read-only database queries
3. `src/Hoard/Effects/DBWrite.hs` - Write transactions

## Files to Modify

1. `package.yaml` - Add dependencies
2. `src/Hoard/Effects.hs` - Integrate into effect stack
3. `hoard.cabal` - Will be regenerated by hpack

## Testing Strategy

After implementation:
1. Verify the project builds successfully
2. Check that effects are properly integrated in the stack
3. Ensure connection pool can be created with test configuration
4. Validate that the effect ordering doesn't cause issues

## Notes

- The implementation focuses on the infrastructure; actual Rel8 queries and table definitions will be added separately
- Error handling will need a proper Error effect or exception handling strategy
- Logging will need to be coordinated with any existing logging infrastructure
- The connection pool is shared across the application and passed through the Config
